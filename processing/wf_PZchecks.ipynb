{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import json\n",
    "import h5py\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tinydb as db\n",
    "from tinydb.storages import MemoryStorage\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use('../clint.mpl')\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "import boost_histogram as bh\n",
    "import pickle as pl\n",
    "\n",
    "from pygama import DataGroup\n",
    "import pygama.lh5 as lh5\n",
    "import pygama.analysis.histograms as pgh\n",
    "import pygama.analysis.peak_fitting as pgf\n",
    "from pygama.dsp.WaveformBrowser import WaveformBrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGroup('./cage.json', load=True)\n",
    "run = 136\n",
    "cycle = 1481\n",
    "# str_query = f'run=={run} and skip==False'\n",
    "str_query = f'cycle=={cycle} and skip==False'\n",
    "dg.fileDB.query(str_query, inplace=True)\n",
    "view_cols = ['runtype', 'run', 'cycle', 'startTime', 'runtime', 'threshold']\n",
    "print(dg.fileDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get runtime, startime, runtype\n",
    "\n",
    "runtype_list = np.array(dg.fileDB['runtype'])\n",
    "runtype = runtype_list[0]\n",
    "\n",
    "rt_min = dg.fileDB['runtime'].sum()\n",
    "u_start = dg.fileDB.iloc[0]['startTime']\n",
    "t_start = pd.to_datetime(u_start, unit='s') # str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scan position\n",
    "\n",
    "if runtype == 'alp':\n",
    "    alphaDB = pd.read_hdf('alphaDB.h5')\n",
    "    scan_pos = alphaDB.loc[alphaDB['run']==run]\n",
    "    radius = np.array(scan_pos['radius'])[0]\n",
    "    angle = np.array(scan_pos['source'])[0]\n",
    "    print(f'Radius: {radius}; Source Angle: {angle}')\n",
    "# else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with dsp or hit files?\n",
    "\n",
    "# hit = True \n",
    "hit = False #ie working with dsp files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with calibrated or uncalibrated data?\n",
    "\n",
    "# cal = True #calibrated data\n",
    "cal = False #uncalibrated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working in your own directory or with the CAGE_lh5 directory?\n",
    "\n",
    "user = False # CAGE_lh5 directory\n",
    "# user = True # hit filesin my personal directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant files\n",
    "\n",
    "lh5_dir = dg.lh5_user_dir if user else dg.lh5_dir\n",
    "# lh5_dir = '/global/homes/g/gothman/projecta/CAGE_lh5_joule'\n",
    "print(lh5_dir)\n",
    "\n",
    "# if hit files\n",
    "if hit == True:\n",
    "    file_list = lh5_dir + dg.fileDB['hit_path'] + '/' + dg.fileDB['hit_file']\n",
    "    \n",
    "else:\n",
    "    file_list = lh5_dir + dg.fileDB['dsp_path'] + '/' + dg.fileDB['dsp_file']\n",
    "    \n",
    "print(f'lh5_dir: {lh5_dir}')\n",
    "print(f'file list: {file_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe\n",
    "\n",
    "if (cal == True) and (hit == True):\n",
    "    df = lh5.load_dfs(file_list, ['energy', 'trapEmax', 'trapEftp', 'trapEmax_cal', 'bl','bl_sig','A_10','AoE', 'ts_sec', 'dcr_raw', 'dcr_ftp', 'dcr_max', 'tp_0', 'tp_10', 'tp_90', 'tp_50', 'tp_80', 'tp_max'], 'ORSIS3302DecoderForEnergy/hit')\n",
    "    \n",
    "elif (cal == True) and (hit == False):\n",
    "    df = lh5.load_dfs(file_list, ['energy', 'trapEmax', 'trapEftp', 'trapEmax_cal', 'bl','bl_sig','A_10','AoE', 'dcr_raw', 'dcr_ftp', 'dcr_max', 'tp_0', 'tp_10', 'tp_90', 'tp_50', 'tp_80', 'tp_max'], 'ORSIS3302DecoderForEnergy/dsp')\n",
    "\n",
    "elif (cal == False) and (hit == True):\n",
    "    df = lh5.load_dfs(file_list, ['energy', 'trapEmax', 'trapEftp', 'bl','bl_sig','A_10','AoE', 'ts_sec', 'dcr_raw', 'dcr_ftp', 'dcr_max', 'tp_0', 'tp_10', 'tp_90', 'tp_50', 'tp_80', 'tp_max'], 'ORSIS3302DecoderForEnergy/hit')\n",
    "    \n",
    "elif (cal == False) and (hit == False):\n",
    "    #df = lh5.load_dfs(file_list, ['energy', 'trapEmax', 'trapEftp', 'bl','bl_sig','A_10','AoE', 'dcr_raw', 'dcr_ftp', 'dcr_max', 'tp_0', 'tp_10', 'tp_90', 'tp_50', 'tp_80', 'tp_max'], 'ORSIS3302DecoderForEnergy/dsp')\n",
    "    df = lh5.load_dfs(file_list, ['energy', 'trapEmax', 'trapEftp', 'bl','bl_sig', 'bl_slope', 'lf_max', 'A_10','AoE', 'dcr', 'tp_0', 'tp_10', 'tp_90', 'tp_50', 'tp_80', 'tp_max'], 'ORSIS3302DecoderForEnergy/dsp')\n",
    "\n",
    "\n",
    "else:\n",
    "    print('dont know what to do here! need to specify if working with calibrated/uncalibrated data, or dsp/hit files')\n",
    "\n",
    "# df_hit = lh5.load_dfs(file_list, ['trapEmax', 'trapEmax_cal', 'bl','bl_sig','A_10','AoE', 'ts_sec', 'dcr_raw', 'dcr_ftp', 'dcr_max', 'tp_0', 'tp_10', 'tp_90', 'tp_50', 'tp_80', 'tp_max'], 'ORSIS3302DecoderForEnergy/hit')\n",
    "# df_hit = lh5.load_dfs(alpha_hit_list, ['trapEmax', 'bl','bl_sig','A_10','ts_sec', 'dcr_raw'], 'ORSIS3302DecoderForEnergy/hit')\n",
    "# print(df_hit)\n",
    "# print(df_hit.columns)\n",
    "\n",
    "# dsc = df[['bl','bl_sig','A_10','AoE', 'dcr_raw', 'dcr_ftp', 'dcr_max']].describe()\n",
    "# # dsc = df_hit[['bl','bl_sig','A_10','ts_sec', 'dcr_raw']].describe()\n",
    "# print(dsc)\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lh5_dir = dg.lh5_user_dir #if user else dg.lh5_dir\n",
    "# print(lh5_dir)\n",
    "# hit_list = lh5_dir + dg.fileDB['hit_path'] + '/' + dg.fileDB['hit_file']\n",
    "# print(hit_list)\n",
    "# df_hit = lh5.load_dfs(hit_list, ['trapEmax', 'trapEmax_cal', 'trapEftp', 'bl','bl_sig','A_10','AoE', 'ts_sec', 'dcr_raw', 'dcr_ftp', 'dcr_max', 'tp_10', 'tp_90', 'tp_50', 'tp_80', 'tp_max'], 'ORSIS3302DecoderForEnergy/hit')\n",
    "# # df_hit = lh5.load_dfs(alpha_hit_list, ['trapEmax', 'bl','bl_sig','A_10','ts_sec', 'dcr_raw'], 'ORSIS3302DecoderForEnergy/hit')\n",
    "# # print(df_hit)\n",
    "# print(df_hit.columns)\n",
    "\n",
    "# dsc = df_hit[['bl','bl_sig','A_10','AoE', 'ts_sec', 'dcr_raw', 'dcr_ftp', 'dcr_max']].describe()\n",
    "# # dsc = df_hit[['bl','bl_sig','A_10','ts_sec', 'dcr_raw']].describe()\n",
    "# print(dsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etype = 'trapEftp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams, cycler\n",
    "import matplotlib as mpl\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [14, 10]\n",
    "\n",
    "waveforms = []\n",
    "time= []\n",
    "e_list = []\n",
    "n_eranges = 50\n",
    "nwfs= 50\n",
    "emin = 5000\n",
    "emax = 15000\n",
    "\n",
    "eranges = np.linspace(emin, emax, n_eranges) #trying to get about 60 keV energy slices\n",
    "for e in eranges:\n",
    "    elo = e-(0.01*e)\n",
    "    ehi = e+(0.01*e)\n",
    "    idx = df[etype].loc[(df[etype] >= elo) &\n",
    "                            (df[etype] <= ehi)].index[:nwfs]\n",
    "    raw_store = lh5.Store()\n",
    "    tb_name = 'ORSIS3302DecoderForEnergy/raw'\n",
    "    lh5_dir = dg.lh5_dir\n",
    "    raw_list = lh5_dir + dg.fileDB['raw_path'] + '/' + dg.fileDB['raw_file']\n",
    "    f_raw = raw_list.values[0] # fixme, only works for one file rn\n",
    "    data_raw, nrows = raw_store.read_object(tb_name, f_raw, start_row=0, n_rows=idx[-1]+1)\n",
    "\n",
    "    wfs_all = (data_raw['waveform']['values']).nda\n",
    "    wfs = wfs_all[idx.values, :]\n",
    "    bl_means = wfs[:,:800].mean(axis=1)\n",
    "    wf_blsub = (wfs.transpose() - bl_means).transpose()\n",
    "    ts = np.arange(0, wf_blsub.shape[1]-1, 1)\n",
    "    super_wf = np.mean(wf_blsub, axis=0)\n",
    "    wf_max = np.amax(super_wf)\n",
    "    superpulse = np.divide(super_wf, wf_max)\n",
    "    waveforms.append(superpulse)\n",
    "    time.append(ts)\n",
    "    e_list.append(e)\n",
    "#     print(wf_max)\n",
    "#     print(np.mean(wf_blsub[0,:500]))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = plt.axes()\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, n_eranges))\n",
    "print(len(colors))\n",
    "\n",
    "\n",
    "\n",
    "c = np.arange(0, n_eranges)\n",
    "\n",
    "norm = mpl.colors.Normalize(vmin=c.min(), vmax=c.max())\n",
    "cmap = mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.jet)\n",
    "cmap.set_array([])\n",
    "\n",
    "\n",
    "\n",
    "for n in range(n_eranges):\n",
    "#     print(colors[n][0])\n",
    "    plt.plot(ts, waveforms[n][:len(waveforms[n])-1], c=cmap.to_rgba(n))\n",
    "    \n",
    "cb = fig.colorbar(cmap, ticks=list(eranges))\n",
    "cb.set_label(\"Energy\", ha = 'right', va='center', rotation=270, fontsize=20)\n",
    "cb.ax.tick_params(labelsize=18)\n",
    "    \n",
    "plt.xlim(3800, 8000)\n",
    "plt.ylim(0.4, 1.01)\n",
    "plt.setp(ax.get_xticklabels(), fontsize=18)\n",
    "plt.setp(ax.get_yticklabels(), fontsize=18)\n",
    "plt.title(f'Waveforms, {emin}-{emax} trapEftp, {n_eranges} steps', fontsize=20)\n",
    "plt.xlabel('clock cycles', fontsize=20)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legend-base",
   "language": "python",
   "name": "legend-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
